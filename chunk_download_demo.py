#!/usr/bin/env python3
"""
åˆ†å—ä¸‹è½½æ¼”ç¤ºç¨‹åº
ä½¿ç”¨æ”¯æŒRangeè¯·æ±‚çš„æµ‹è¯•æ–‡ä»¶æ¥æ¼”ç¤ºåˆ†å—ä¸‹è½½çš„å·¥ä½œåŸç†
"""

import os
import sys
import time
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
import requests
import argparse

class ChunkDownloadDemo:
    def __init__(self, max_threads=4, chunk_size=1024*1024):
        self.max_threads = max_threads
        self.chunk_size = chunk_size
        self.progress_lock = threading.Lock()
        self.total_downloaded = 0
        self.total_size = 0
        self.start_time = None
        self.chunk_progress = {}
        
    def test_url_support(self, url):
        """æµ‹è¯•URLæ˜¯å¦æ”¯æŒRangeè¯·æ±‚"""
        try:
            headers = {'Range': 'bytes=0-1023'}
            response = requests.head(url, headers=headers, timeout=10)
            
            if response.status_code == 206:
                print(f"âœ… æœåŠ¡å™¨æ”¯æŒRangeè¯·æ±‚ (çŠ¶æ€ç : {response.status_code})")
                return True
            elif response.status_code == 200:
                support = 'accept-ranges' in response.headers
                if support:
                    print(f"âœ… æœåŠ¡å™¨æ”¯æŒRangeè¯·æ±‚ (Accept-Ranges: {response.headers.get('accept-ranges')})")
                else:
                    print(f"âŒ æœåŠ¡å™¨ä¸æ”¯æŒRangeè¯·æ±‚")
                return support
            else:
                print(f"âŒ æœåŠ¡å™¨ä¸æ”¯æŒRangeè¯·æ±‚ (çŠ¶æ€ç : {response.status_code})")
                return False
                
        except Exception as e:
            print(f"âŒ æµ‹è¯•Rangeæ”¯æŒå¤±è´¥: {str(e)}")
            return False
    
    def get_file_size(self, url):
        """è·å–æ–‡ä»¶å¤§å°"""
        try:
            response = requests.head(url, timeout=10)
            
            if 'content-length' in response.headers:
                size = int(response.headers['content-length'])
                print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {size / (1024*1024):.2f} MB ({size:,} å­—èŠ‚)")
                return size
            else:
                print("âŒ æ— æ³•è·å–æ–‡ä»¶å¤§å°")
                return 0
                
        except Exception as e:
            print(f"âŒ è·å–æ–‡ä»¶å¤§å°å¤±è´¥: {str(e)}")
            return 0
    
    def download_chunk(self, url, start, end, chunk_id, temp_dir):
        """ä¸‹è½½å•ä¸ªæ•°æ®å—"""
        headers = {'Range': f'bytes={start}-{end}'}
        chunk_file = os.path.join(temp_dir, f'chunk_{chunk_id:04d}.tmp')
        
        print(f"ğŸ”„ çº¿ç¨‹ {chunk_id}: å¼€å§‹ä¸‹è½½å­—èŠ‚ {start:,} - {end:,}")
        
        try:
            response = requests.get(url, headers=headers, stream=True, timeout=30)
            response.raise_for_status()
            
            chunk_size_downloaded = 0
            expected_size = end - start + 1
            
            with open(chunk_file, 'wb') as f:
                for data in response.iter_content(chunk_size=8192):
                    if data:
                        f.write(data)
                        chunk_size_downloaded += len(data)
                        
                        # æ›´æ–°è¿›åº¦
                        with self.progress_lock:
                            self.total_downloaded += len(data)
                            self.update_progress()
            
            actual_size = os.path.getsize(chunk_file)
            print(f"âœ… çº¿ç¨‹ {chunk_id}: å®Œæˆï¼Œä¸‹è½½ {actual_size:,} å­—èŠ‚")
            
            return chunk_id, chunk_size_downloaded, None
            
        except Exception as e:
            print(f"âŒ çº¿ç¨‹ {chunk_id}: å¤±è´¥ - {str(e)}")
            return chunk_id, 0, str(e)
    
    def update_progress(self):
        """æ›´æ–°ä¸‹è½½è¿›åº¦"""
        if self.total_size > 0:
            progress = (self.total_downloaded / self.total_size) * 100
            elapsed_time = time.time() - self.start_time
            
            if elapsed_time > 0:
                speed = self.total_downloaded / elapsed_time
                speed_mb = speed / (1024 * 1024)
                
                downloaded_mb = self.total_downloaded / (1024 * 1024)
                total_mb = self.total_size / (1024 * 1024)
                
                progress_bar = self.get_progress_bar(progress)
                
                print(f"\r{progress_bar} {progress:.1f}% | "
                      f"{downloaded_mb:.1f}MB/{total_mb:.1f}MB | "
                      f"{speed_mb:.2f}MB/s", end='', flush=True)
    
    def get_progress_bar(self, progress, width=20):
        """ç”Ÿæˆè¿›åº¦æ¡"""
        filled = int(width * progress / 100)
        bar = 'â–ˆ' * filled + 'â–‘' * (width - filled)
        return f"[{bar}]"
    
    def merge_chunks(self, temp_dir, output_file, num_chunks):
        """åˆå¹¶æ‰€æœ‰æ•°æ®å—"""
        print(f"\nğŸ”§ å¼€å§‹åˆå¹¶ {num_chunks} ä¸ªæ•°æ®å—...")
        
        try:
            total_merged = 0
            with open(output_file, 'wb') as outfile:
                for i in range(num_chunks):
                    chunk_file = os.path.join(temp_dir, f'chunk_{i:04d}.tmp')
                    if os.path.exists(chunk_file):
                        chunk_size = os.path.getsize(chunk_file)
                        print(f"ğŸ“„ åˆå¹¶æ•°æ®å— {i}: {chunk_size:,} å­—èŠ‚")
                        
                        with open(chunk_file, 'rb') as infile:
                            data = infile.read()
                            outfile.write(data)
                            total_merged += len(data)
                        
                        os.remove(chunk_file)
                    else:
                        print(f"âš ï¸  æ•°æ®å— {i} ä¸å­˜åœ¨")
            
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            if os.path.exists(temp_dir):
                os.rmdir(temp_dir)
            
            print(f"âœ… åˆå¹¶å®Œæˆ: {output_file}")
            print(f"ğŸ“¦ åˆå¹¶åæ–‡ä»¶å¤§å°: {total_merged:,} å­—èŠ‚ ({total_merged/(1024*1024):.2f} MB)")
            
            return True
            
        except Exception as e:
            print(f"âŒ åˆå¹¶å¤±è´¥: {str(e)}")
            return False
    
    def download_file(self, url, output_file):
        """åˆ†å—ä¸‹è½½æ–‡ä»¶"""
        print("ğŸ¯ å¼€å§‹åˆ†å—ä¸‹è½½æ¼”ç¤º")
        print("=" * 60)
        
        # æµ‹è¯•Rangeæ”¯æŒ
        print("ğŸ§ª æµ‹è¯•æœåŠ¡å™¨Rangeæ”¯æŒ...")
        if not self.test_url_support(url):
            print("âŒ æœåŠ¡å™¨ä¸æ”¯æŒåˆ†å—ä¸‹è½½")
            return False
        
        # è·å–æ–‡ä»¶å¤§å°
        print("\nğŸ“ è·å–æ–‡ä»¶ä¿¡æ¯...")
        file_size = self.get_file_size(url)
        if file_size == 0:
            print("âŒ æ— æ³•è·å–æ–‡ä»¶å¤§å°")
            return False
        
        self.total_size = file_size
        
        # è®¡ç®—åˆ†å—ç­–ç•¥
        num_chunks = min(self.max_threads, max(1, file_size // self.chunk_size))
        chunk_size = file_size // num_chunks
        
        print(f"\nğŸ”€ åˆ†å—ç­–ç•¥:")
        print(f"   æ€»çº¿ç¨‹æ•°: {num_chunks}")
        print(f"   æ¯å—å¤§å°: {chunk_size:,} å­—èŠ‚ ({chunk_size/(1024*1024):.2f} MB)")
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = os.path.join(os.path.dirname(output_file), f'temp_chunks_{int(time.time())}')
        os.makedirs(temp_dir, exist_ok=True)
        
        print(f"\nğŸš€ å¼€å§‹å¤šçº¿ç¨‹ä¸‹è½½...")
        print("=" * 60)
        
        self.start_time = time.time()
        self.total_downloaded = 0
        
        # æ˜¾ç¤ºæ¯ä¸ªçº¿ç¨‹çš„åˆ†å·¥
        for i in range(num_chunks):
            start = i * chunk_size
            end = start + chunk_size - 1
            if i == num_chunks - 1:
                end = file_size - 1
            print(f"ğŸ§µ çº¿ç¨‹ {i}: å­—èŠ‚ {start:,} - {end:,} ({end-start+1:,} å­—èŠ‚)")
        
        print()
        
        # å¯åŠ¨å¤šçº¿ç¨‹ä¸‹è½½
        with ThreadPoolExecutor(max_workers=num_chunks) as executor:
            futures = []
            
            for i in range(num_chunks):
                start = i * chunk_size
                end = start + chunk_size - 1
                if i == num_chunks - 1:
                    end = file_size - 1
                
                future = executor.submit(self.download_chunk, url, start, end, i, temp_dir)
                futures.append(future)
            
            # ç­‰å¾…æ‰€æœ‰ä¸‹è½½å®Œæˆ
            failed_chunks = []
            for future in as_completed(futures):
                chunk_id, downloaded, error = future.result()
                if error:
                    failed_chunks.append(chunk_id)
        
        print()  # æ¢è¡Œ
        
        if failed_chunks:
            print(f"âŒ æœ‰ {len(failed_chunks)} ä¸ªæ•°æ®å—ä¸‹è½½å¤±è´¥")
            return False
        
        # åˆå¹¶æ–‡ä»¶
        success = self.merge_chunks(temp_dir, output_file, num_chunks)
        
        if success:
            elapsed_time = time.time() - self.start_time
            avg_speed = (file_size / (1024*1024)) / elapsed_time if elapsed_time > 0 else 0
            
            print("\n" + "=" * 60)
            print("ğŸ‰ åˆ†å—ä¸‹è½½æ¼”ç¤ºå®Œæˆ!")
            print(f"â±ï¸  æ€»ç”¨æ—¶: {elapsed_time:.2f} ç§’")
            print(f"ğŸ“ˆ å¹³å‡é€Ÿåº¦: {avg_speed:.2f} MB/s")
            print(f"ğŸ’¾ æ–‡ä»¶ä½ç½®: {output_file}")
            
            # éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
            actual_size = os.path.getsize(output_file)
            if actual_size == file_size:
                print("âœ… æ–‡ä»¶å®Œæ•´æ€§éªŒè¯é€šè¿‡")
            else:
                print(f"âš ï¸  æ–‡ä»¶å¤§å°ä¸åŒ¹é…: æœŸæœ› {file_size:,}, å®é™… {actual_size:,}")
        
        return success

def main():
    parser = argparse.ArgumentParser(description="åˆ†å—ä¸‹è½½æ¼”ç¤ºç¨‹åº")
    parser.add_argument('url', nargs='?', 
                       default='https://httpbin.org/bytes/10485760',  # 10MBæµ‹è¯•æ–‡ä»¶
                       help='è¦ä¸‹è½½çš„æ–‡ä»¶URL (é»˜è®¤: httpbin 10MBæµ‹è¯•æ–‡ä»¶)')
    parser.add_argument('--output', '-o', default='./downloads/demo_file.bin',
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--threads', '-t', type=int, default=4,
                       help='çº¿ç¨‹æ•° (é»˜è®¤: 4)')
    parser.add_argument('--chunk-size', '-c', type=int, default=1,
                       help='æ•°æ®å—å¤§å° MB (é»˜è®¤: 1)')
    
    args = parser.parse_args()
    
    # ä¸€äº›æ¨èçš„æµ‹è¯•URL
    test_urls = {
        'httpbin_10mb': 'https://httpbin.org/bytes/10485760',  # 10MB
        'httpbin_5mb': 'https://httpbin.org/bytes/5242880',    # 5MB
        'httpbin_1mb': 'https://httpbin.org/bytes/1048576',    # 1MB
    }
    
    print("ğŸ§ª åˆ†å—ä¸‹è½½æ¼”ç¤ºç¨‹åº")
    print("=" * 60)
    print("è¿™ä¸ªç¨‹åºæ¼”ç¤ºå¦‚ä½•å°†å¤§æ–‡ä»¶åˆ†æˆå¤šä¸ªå—å¹¶è¡Œä¸‹è½½")
    print(f"ğŸ”§ é…ç½®: {args.threads} çº¿ç¨‹, {args.chunk_size}MB å—å¤§å°")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {args.output}")
    print(f"ğŸŒ ä¸‹è½½URL: {args.url}")
    
    if args.url in test_urls.values():
        print("ğŸ“ ä½¿ç”¨æµ‹è¯•URLï¼Œè¿™ä¸ªURLæ”¯æŒRangeè¯·æ±‚")
    
    print("=" * 60)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(os.path.dirname(args.output), exist_ok=True)
    
    # åˆ›å»ºä¸‹è½½å™¨
    downloader = ChunkDownloadDemo(
        max_threads=args.threads,
        chunk_size=args.chunk_size * 1024 * 1024
    )
    
    # å¼€å§‹ä¸‹è½½
    success = downloader.download_file(args.url, args.output)
    
    if not success:
        print("\nğŸ’¥ æ¼”ç¤ºå¤±è´¥ï¼")
        sys.exit(1)
    else:
        print("\nğŸŠ æ¼”ç¤ºæˆåŠŸå®Œæˆï¼")

if __name__ == "__main__":
    main()
